
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.5.3">
    
    
      
        <title>IML Notes *Chapter 1* - IML Notes Site</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7a952b86.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cbb835fc.min.css">
        
          
          
          <meta name="theme-color" content="#000000">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="black" data-md-color-accent="deep-orange">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#iml-notes-chapter-1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="IML Notes Site" class="md-header__button md-logo" aria-label="IML Notes Site" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            IML Notes Site
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              IML Notes *Chapter 1*
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="IML Notes Site" class="md-nav__button md-logo" aria-label="IML Notes Site" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    IML Notes Site
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Welcome to MkDocs
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          IML Notes *Chapter 1*
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        IML Notes *Chapter 1*
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    数学基础
  </a>
  
    <nav class="md-nav" aria-label="数学基础">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    线性代数
  </a>
  
    <nav class="md-nav" aria-label="线性代数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    矩阵合同
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    正定性
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    矩阵相似
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    伴随矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    矩阵的迹
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    矩阵范数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    矩阵导数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    矩阵分解
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    概率论与数理统计
  </a>
  
    <nav class="md-nav" aria-label="概率论与数理统计">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    概率分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    熵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kl" class="md-nav__link">
    KL 散度
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    优化
  </a>
  
    <nav class="md-nav" aria-label="优化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    凸集和凸函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    优化问题
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    数学基础
  </a>
  
    <nav class="md-nav" aria-label="数学基础">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    线性代数
  </a>
  
    <nav class="md-nav" aria-label="线性代数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    矩阵合同
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    正定性
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    矩阵相似
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    伴随矩阵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    矩阵的迹
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    矩阵范数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    矩阵导数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    矩阵分解
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    概率论与数理统计
  </a>
  
    <nav class="md-nav" aria-label="概率论与数理统计">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    概率分布
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_13" class="md-nav__link">
    熵
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kl" class="md-nav__link">
    KL 散度
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_14" class="md-nav__link">
    优化
  </a>
  
    <nav class="md-nav" aria-label="优化">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_15" class="md-nav__link">
    凸集和凸函数
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_16" class="md-nav__link">
    优化问题
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="iml-notes-chapter-1">IML Notes <em>Chapter 1</em></h1>
<h2 id="_1">数学基础</h2>
<h3 id="_2">线性代数</h3>
<h4 id="_3">矩阵合同</h4>
<p>在线性代数，特别是二次型理论中，常常用到矩阵间的合同关系。两个矩阵 $A$ 和 $B$ 是合同的，是指如果有同数域上的<strong>可逆</strong>矩阵 $P$ ，使得
$$
A=P^{\mathrm{T}} B P
$$
- 合同关系是等价关系。
- 合同类矩阵具有相等的秩和正惯性指数，秩和正惯性指数是合同关系下的完全不变量，即如果两个矩阵合同等价于他们的秩和正惯性指数相等。
- 每个对称矩阵都合同于一个对角矩阵，后者称为一个标准形。</p>
<h4 id="_4">正定性</h4>
<p>一个 $n \times n$ 的实对称矩阵 $M$ 是正定的，当且仅当对于所有的<strong>非零、实系数</strong>向量 $\mathbf{z}$ ，都有 $\mathbf{z}^T M \mathbf{z}&gt;0$ 。</p>
<p>$M$ 是半正定矩阵当且仅当对于所 有非零向量 $\mathbf{z} \in \mathbb{R}^n$ (或 $\mathbf{z} \in \mathbb{C}^n$ )，都有 $z^<em> M z \geq 0$ 。（$</em>$表示共轭转置）
$M$ 是半负定矩阵当且仅当对于 所有非零向量 $\mathbf{z} \in \mathbb{R}^n$ (或 $\mathbf{z} \in \mathbb{C}^n$ )，都有 $z^* M z \leq 0$ 。</p>
<ul>
<li>若 $M$ 为半正定矩阵，可以记作 $M \geq 0$ 。如果 $M$ 是正定矩阵，可以记作 $M&gt;0$ 。</li>
<li>如果 $M 、 N$ 是正定阵，那么 $M+N 、 M N M$ 与 $N M N$ 都是正定 的。如果 $M N=N M$ ，那么 $M N$ 仍是正定阵。</li>
<li>如果 $M, N \geq 0$ 为实系数矩阵，则 $\operatorname{tr}(M N) \geq 0$ 。</li>
</ul>
<h4 id="_5">矩阵相似</h4>
<p>在线性代数中，相似关系是两个矩阵之间的一种等价关系。两个 $n \times n$ 矩阵 $A$ 与 $B$ 为相似矩阵当且仅当存在一个 $n \times n$ 的可逆矩阵 $P$ ，使得:
$$
P^{-1} A P=B
$$
判断两个矩阵是否相似的辅助方法：</p>
<ol>
<li>
<p>判断<a href="https://zh.wikipedia.org/wiki/特征值">特征值</a>是否相等； </p>
</li>
<li>
<p>判断<a href="https://zh.wikipedia.org/wiki/行列式">行列式</a>是否相等； </p>
</li>
<li>
<p>判断<a href="https://zh.wikipedia.org/wiki/跡">迹</a>是否相等； </p>
</li>
<li>
<p>判断<a href="https://zh.wikipedia.org/wiki/秩_(线性代数)">秩</a>是否相等；</p>
</li>
</ol>
<p>以上条件可以作为判断矩阵是否相似的必要条件，而非充分条件。</p>
<ul>
<li>相似关系是等价关系。</li>
<li>如果两个相似矩阵 $A$ 和 $B$ 之间的转换矩阵 $P$ 是一个酉矩阵（$U^<em>U=UU^</em>=I$），那么就称 $A$ 和 $B$ “酉相似"。</li>
<li>两个相似的矩阵拥有同样的<a href="https://zh.wikipedia.org/wiki/特征值">特征值</a>，尽管相应的特征向量一般不同。</li>
</ul>
<h4 id="_6">伴随矩阵</h4>
<p>设矩阵 $A=\left(a_{i j}\right)<em>{n \times n}$ ，将矩阵 $A$ 的元素 $a</em>{i j}$ 所在的第 i 行第 j 列元素划去后，剩余的各元素按原来的排列顺序组成的 $\mathrm{n}-1$ 阶矩阵所确定的行列式称为元素 $a_{i j}$ 的余子式，记为 $M_{i j}$ ，称 $A_{i j}=(-1)^{i+j} M_{i j}$ 为元素 $a_{i j}$ 的代数余子式。</p>
<p>方阵 $A=\left(a_{i j}\right)<em>{n \times n}$ 的各元素的代数余子式 $A</em>{i j}$ 所构成的如下矩阵 $A^<em>$ :
$$
\begin{array}{cccc}
A_{11} &amp; A_{21} &amp; \cdots &amp; A_{n 1} \
A_{12} &amp; A_{22} &amp; \cdots &amp; A_{n 2} \
\vdots &amp; \vdots &amp; &amp; \vdots \
A_{1 n} &amp; A_{2 n} &amp; \cdots &amp; A_{n n}
\end{array}
$$
该矩阵 $A^</em>$ 称为矩阵 $A$ 的伴随矩阵。</p>
<ul>
<li>$A$ 可逆当且仅当 $A^*$ 可逆；</li>
<li>如果 $A$ 可逆，则 $A^<em>=|A| A^{-1}$ ；（</em><em>重要</em>*，下面 $|A|:=det(A)$）</li>
<li>对于 $A^*$ 的秩有:</li>
</ul>
<p>$$
\begin{aligned}
&amp;\operatorname{rank}\left(A^<em>\right)=n, \operatorname{rank}(A)=n \
&amp;\operatorname{rank}\left(A^</em>\right)=1, \operatorname{rank}(A)=n-1 \
&amp;\operatorname{rank}\left(A^<em>\right)=0, \operatorname{rank}(A)&lt;n-1
\end{aligned}
$$
- $\left|A^</em>\right|=|A|^{n-1}$;
- $(k A)^<em>=k^{n-1} A^</em>$
- 若 $A$ 可逆，则 $\left(A^{-1}\right)^<em>=\left(A^</em>\right)^{-1}$ ；
- $\left(A^T\right)^<em>=\left(A^</em>\right)^T$
- $(A B)^<em>=B^</em> A^<em>$ 。
- $\mathrm{AA}^</em>=\mathrm{A}^* \mathrm{~A}=det(\mathrm{A}) I$</p>
<h4 id="_7">矩阵的迹</h4>
<p>在线性代数中，一个 $n \times n$ 的矩阵 $\mathbf{A}$ 的迹 (或迹数)，是指 $\mathbf{A}$ 的主对角线 (从左上方至右下方的对角线) 上各个元素的总和，一般记作 $\operatorname{tr}(\mathbf{A})$ 或 $\operatorname{Sp}(\mathbf{A})$ :
$$
\operatorname{tr}(\mathbf{A})=\mathbf{A}<em>{1,1}+\mathbf{A}</em>{2,2}+\cdots+\mathbf{A}<em>{n, n}
$$
其中 $\mathbf{A}</em>{i, j}$ 代表矩阵的第i行列上的元素的值。</p>
<ul>
<li>
<p>一个矩阵的迹是其特征值的总和 (按代数重数计算) 。</p>
</li>
<li>
<p>$tr(A+B)=tr(A)+tr(B)$，$tr(aA)=a·tr(A)$，$tr(A)=tr(A^T)$</p>
</li>
<li>
<p>$A(n\times m),B(m\times n)$，则 $tr(AB)=tr(BA)$，按矩阵乘法定义可证。</p>
</li>
<li>
<p>计算若干个同样大小的方形矩阵的乘积的迹数时，可以<strong>循环</strong>改变乘积中方形矩阵相乘的顺序，而最终的结果不变。$tr(ABC)=tr(BCA),$ 但 $tr(ABC)\ne tr(ACB)$（不循环）。</p>
</li>
<li>
<p>迹数拥有相似不变性。如果矩阵 <strong>A</strong> 和 <strong>B</strong> 的话，它们会有相同的迹。</p>
</li>
<li>
<p>一个 $n \times n$ 的方形矩阵 $\mathbf{A}$ 的特征多项式 $P_A(\lambda)$ 如下：
  $$
  P_A(\lambda)=\operatorname{det}(\mathbf{A}-\lambda \mathbf{I})
  $$
  特征多项式是一个关于 $\lambda$ 的 $\mathbf{n}$ 次多项式，它的常数项是 $\mathbf{A}$ 的行列式的值，最高次项是 $(-1)^n \lambda^n$ ，而接下来的 $\mathbf{n}-1$ 次项就是 $(-1)^{n-1} \operatorname{tr}(\mathbf{A}) \lambda^{n-1}$ ，也就是说:
  $$
  P_A(\lambda)=(-1)^n \lambda^n+(-1)^{n-1} \operatorname{tr}(\mathbf{A}) \lambda^{n-1}+\cdots+\operatorname{det}(\mathbf{A})
  $$</p>
</li>
</ul>
<h4 id="_8">矩阵范数</h4>
<p>衡量一个矩阵 “大小” 的函数 $f(\mathbf{A})$，满足三个条件：
$$
\begin{aligned}
&amp;f(\boldsymbol{A}) \geq \mathbf{0} ， \text { 等号成立当且仅当 } \boldsymbol{A}=0 \
&amp;f(\alpha \boldsymbol{A})=|\alpha| f(\boldsymbol{A})，\alpha\in \mathbf{A}的数域 \
&amp;f(\boldsymbol{A}+\boldsymbol{B}) \leq f(\boldsymbol{A})+f(\boldsymbol{B})
\end{aligned}
$$</p>
<ul>
<li><strong>Frobenius norm（弗罗贝尼乌斯范数）</strong></li>
</ul>
<p>相当于把矩阵看成一个 $m\times n$ 的向量。</p>
<p>$\displaystyle|A|<em>F=\sqrt{\sum</em>{i=1}^m \sum_{j=1}^n\left|a_{i j}\right|^2}=\sqrt{\operatorname{trace}\left(A^* A\right)}$</p>
<ul>
<li><strong>p-诱导范数</strong></li>
</ul>
<p>对于向量来说，p-范数定义为 $|\boldsymbol{x}|_p=\sqrt[p]{x_1^p+\cdots+x_d^p}$。</p>
<p>矩阵的p-诱导范数：</p>
<p>$\displaystyle|A|<em>p=\max </em>{x \neq 0} \frac{|A x|<em>p}{|x|_p}=\max </em>{x \neq 0} \frac{\left(\sum_{i=1}^m\left|\sum_{j=1}^n a_{i j} x_j\right|^p\right)^{1 / p}}{\left(\sum_{j=1}^n\left|x_j\right|^p\right)^{1 / p}}$</p>
<ul>
<li>
<p>当 $p=2$ (欧几里德范数) 时，诱导的矩阵范数就是谱范数。矩阵 $A$ 的谱范数是 $A$ 最大的奇异值或半正定矩阵 $A^* A$ 的最大特征值的平方根：</p>
<p>$$
  |A|<em>2=\sqrt{\lambda</em>{\max }\left(A^* A\right)}
  $$</p>
</li>
</ul>
<h4 id="_9">矩阵导数</h4>
<ul>
<li><strong>梯度</strong></li>
</ul>
<p>对向量 $\mathbf{x}$ 来说，其函数的梯度是一个向量：
  $$
  (\mathbf{grad}f(\mathbf{x}))<em>i=\left(\nabla f(\boldsymbol{x})\right)</em>{i}=\frac{\partial f(\mathbf{x})}{\partial x_i}
  $$
  二阶导是一个矩阵（称之为海森矩阵）：
  $$
  \left(\nabla^2 f(\boldsymbol{x})\right)_{i j}=\frac{\partial^2 f(\boldsymbol{x})}{\partial x_i \partial x_j}
  $$
  类似单变量微积分：$f(\mathbf{x})≈f(\mathbf{x}_0)+\text{grad}f(\mathbf{x}_0)·(\mathbf{x-x}_0)$</p>
<ul>
<li>
<p><strong>从各种求导规则引出矩阵函数求导规则</strong></p>
</li>
<li>
<p>向量对标量求导 $\mathbf{y}=(y_1\quad y_2 \quad...\quad y_m)^T$
    $$
    \frac{\partial \mathbf{y}}{\partial x}=\left[\begin{array}{c}
    \frac{\partial y_1}{\partial x} \
    \frac{\partial y_2}{\partial x} \
    \vdots \
    \frac{\partial y_m}{\partial x}
    \end{array}\right]
    $$</p>
</li>
<li>
<p>标量对向量求导 $\mathbf{x}=(x_1\quad x_2 \quad...\quad x_n)^T$
    $$
    \frac{\partial y}{\partial \mathbf{x}}=\left[\begin{array}{llll}
    \frac{\partial y}{\partial x_1} &amp; \frac{\partial y}{\partial x_2} &amp; \cdots &amp; \frac{\partial y}{\partial x_n}
    \end{array}\right]
    $$</p>
</li>
<li>
<p>向量对向量求导 —— 正好是雅可比矩阵</p>
<p>近似公式：$\mathbf{f}(\mathbf{x})-\mathbf{f}(\mathbf{p})=\mathbf{J}_{\mathbf{f}}(\mathbf{p})(\mathbf{x}-\mathbf{p})+o(|\mathbf{x}-\mathbf{p}|) \quad($as $\mathbf{x} \rightarrow \mathbf{p})$
$$
\frac{\partial \mathbf{y}}{\partial \mathbf{x}}=\left[\begin{array}{cccc}
\frac{\partial y_1}{\partial x_1} &amp; \frac{\partial y_1}{\partial x_2} &amp; \cdots &amp; \frac{\partial y_1}{\partial x_n} \
\frac{\partial y_2}{\partial x_1} &amp; \frac{\partial y_2}{\partial x_2} &amp; \cdots &amp; \frac{\partial y_2}{\partial x_n} \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
\frac{\partial y_m}{\partial x_1} &amp; \frac{\partial y_m}{\partial x_2} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_n}
\end{array}\right]
$$</p>
</li>
<li>
<p>矩阵对标量求导 ——即结果的 $(i,j)$ 元等于矩阵的 $(i,j)$ 元对标量求导
    $$
    \frac{\partial \mathbf{Y}}{\partial x}=\left[\begin{array}{cccc}\frac{\partial y_{11}}{\partial x} &amp; \frac{\partial y_{12}}{\partial x} &amp; \cdots &amp; \frac{\partial y_{1 n}}{\partial x} \ \frac{\partial y_{21}}{\partial x} &amp; \frac{\partial y_{22}}{\partial x} &amp; \cdots &amp; \frac{\partial y_{2 n}}{\partial x} \ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \ \frac{\partial y_{m 1}}{\partial x} &amp; \frac{\partial y_{m 2}}{\partial x} &amp; \cdots &amp; \frac{\partial y_{m n}}{\partial x}\end{array}\right]
    $$</p>
</li>
<li>
<p>标量对矩阵求导 ——即结果的 $(i,j)$ 元等于标量对矩阵的 $(i,j)$ 元求导
    $$
    \frac{\partial y}{\partial \mathbf{X}}=\left[\begin{array}{cccc}
    \frac{\partial y}{\partial x_{11}} &amp; \frac{\partial y}{\partial x_{12}} &amp; \cdots &amp; \frac{\partial y}{\partial x_{1 q}} \
    \frac{\partial y}{\partial x_{21}} &amp; \frac{\partial y}{\partial x_{22}} &amp; \cdots &amp; \frac{\partial y}{\partial x_{2 q}} \
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \
    \frac{\partial y}{\partial x_{p 1}} &amp; \frac{\partial y}{\partial x_{p 2}} &amp; \cdots &amp; \frac{\partial y}{\partial x_{p q}}
    \end{array}\right]
    $$</p>
</li>
<li>
<p><strong>矩阵导数</strong></p>
</li>
<li>
<p>$\displaystyle\frac{\partial \operatorname{tr}(\boldsymbol{A B})}{\partial A_{i j}}=B_{j i} \quad \Rightarrow \quad \frac{\partial \operatorname{tr}(\boldsymbol{A B})}{\partial \boldsymbol{A}}=\boldsymbol{B}^{\top} \quad \frac{\partial \operatorname{tr}\left(\boldsymbol{A}^{\top} \boldsymbol{B}\right)}{\partial \boldsymbol{A}}=\boldsymbol{B}$</p>
</li>
<li>$\displaystyle\frac{\partial|A|_F^2}{\partial A}=\frac{\partial \operatorname{tr}\left(A^{\top} A\right)}{\partial A}=2 A$</li>
<li>$\displaystyle\boldsymbol{A}^{-1} \boldsymbol{A}=\boldsymbol{I} \Longrightarrow \frac{\partial \boldsymbol{A}^{-1} \boldsymbol{A}}{\partial x}=\frac{\partial \boldsymbol{A}^{-1}}{\partial x} \boldsymbol{A}+\boldsymbol{A}^{-1} \frac{\partial \boldsymbol{A}}{\partial x}=\mathbf{0} \Rightarrow \frac{\partial \boldsymbol{A}^{-1}}{\partial x}=-\boldsymbol{A}^{-1} \frac{\partial \boldsymbol{A}}{\partial x} \boldsymbol{A}^{-1}$（求导的乘法法则）</li>
<li>$\displaystyle \frac{\partial \operatorname{det}(\boldsymbol{A})}{\partial \boldsymbol{A}}=\boldsymbol{C}=\operatorname{adj}(\boldsymbol{A})^{\top} \Rightarrow \frac{\partial \ln \operatorname{det}(\boldsymbol{A})}{\partial \boldsymbol{A}}=\left(\boldsymbol{A}^{-1}\right)^{\top}$（求导的链式法则）</li>
</ul>
<h4 id="_10">矩阵分解</h4>
<ul>
<li><strong>可对角化矩阵的特征值分解</strong></li>
</ul>
<p>$\boldsymbol{A}=\boldsymbol{V} \operatorname{diag}(\boldsymbol\lambda) \boldsymbol{V}^{-1}$ ， $\boldsymbol\lambda$ 对应特征值，$\boldsymbol V$ 中的每一列为特征向量。</p>
<blockquote>
<p>机器学习算法常常涉及<strong>实对称矩阵</strong>
- 可对角化的
- $V$ 为正交矩阵，满足 $V^{\top} V=V V^{\top}=I$</p>
</blockquote>
<ul>
<li><strong>奇异值分解</strong> ——类似特征值分解，但是对任意矩阵都成立</li>
</ul>
<p>对于任意大小为 $m \times n$ 的矩阵 $\boldsymbol{A}, \boldsymbol{A}^{\top} \boldsymbol{A} \boldsymbol{v}=\lambda \boldsymbol{v}$</p>
<ul>
<li>令 $\mathbf A \mathbf v=\sigma \mathbf u$ ，那么 $\mathbf A^T \sigma \mathbf u=\lambda \mathbf v$ ，分别左乘 $\mathbf A$ 得到 $\mathbf A \mathbf A^{\top} \mathbf u=\displaystyle\frac{\lambda}{\sigma} \mathbf A \mathbf v=\lambda \mathbf u$</li>
<li>$\mathbf u$ 对应 $\mathbf A\mathbf A^T$ 的特征值为 $\lambda$ 的特征向量。</li>
<li>在 $\mathbf{Av}=\sigma \mathbf u$ 两边分别乘以 $\mathbf u^T$ ，那么 $\mathbf u^{\top} \mathbf A \mathbf v=\sigma$ </li>
<li>在 $\mathbf A^T \sigma \mathbf u=\lambda \mathbf v$ 两边分别乘以 $\mathbf v$ ，那么 $\mathbf v^T \mathbf A^T \mathbf u=\frac{\lambda}{\sigma}$</li>
<li>所以 $\sigma^2=\lambda$</li>
</ul>
<p>将 $\mathbf{Av}=\sigma\mathbf{u}$ 写成矩阵形式 $\mathbf{AV=U\Sigma}$</p>
<ul>
<li>$\mathbf{U,V}$ 是正交矩阵，$\boldsymbol{A}=\boldsymbol{A} \boldsymbol{V} \boldsymbol{V}^{\top}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\top}$<ul>
<li>广义逆 $\mathbf{A^+=V\Sigma^{-1}U^T}$</li>
<li>$\Sigma^{-1}$ 的定义见<a href="https://blog.csdn.net/a15779627836/article/details/116804713">这里</a></li>
</ul>
</li>
<li><strong>U</strong> 的列向量为左奇异向量，<strong>V</strong> 的列向量为右奇异向量</li>
<li><strong>Σ</strong> 的大小为m×n，<strong>U</strong>的大小为m×m，<strong>V</strong>的大小为n×n</li>
</ul>
<h3 id="_11">概率论与数理统计</h3>
<h4 id="_12">概率分布</h4>
<ul>
<li>
<p>高斯分布、正态分布</p>
</li>
<li>
<p>$\displaystyle\mathcal{N}\left(x ; \mu, \sigma^2\right)=\sqrt{\frac{1}{2 \pi \sigma^2}} \exp \left(-\frac{1}{2 \sigma^2}(x-\mu)^2\right) \quad$ 均值 $\mu$ 标准差 $\sigma$</p>
</li>
<li>
<p>$\displaystyle\mathcal{N}\left(x ; \mu, \beta^{-1}\right)=\sqrt{\frac{\beta}{2 \pi}} \exp \left(-\frac{\beta}{2}(x-\mu)^2\right) \quad$ 均值 $\mu$ Scale $\beta$</p>
</li>
<li>
<p>多元正态分布</p>
</li>
<li>
<p>$\displaystyle\mathcal{N}(\boldsymbol{x} ; \boldsymbol{\mu}, \boldsymbol{\Sigma})=\frac{1}{\sqrt{(2 \pi)^n \operatorname{det}(\boldsymbol{\Sigma})}} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\top} \mathbf{\Sigma}^{-1}(\boldsymbol{x}-\boldsymbol{\mu})\right)$</p>
</li>
<li>
<p>$\displaystyle\mathcal{N}\left(\boldsymbol{x} ; \boldsymbol{\mu}, \boldsymbol{\beta}^{-1}\right)=\sqrt{\frac{\operatorname{det}(\boldsymbol{\beta})}{(2 \pi)^n}} \exp \left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu})^{\top} \boldsymbol{\beta}(\boldsymbol{x}-\boldsymbol{\mu})\right)$</p>
</li>
<li>
<p>贝塔分布 ——$\mu\in[0,1]$ </p>
</li>
<li>
<p>$\displaystyle\operatorname{Beta}(\mu \mid a, b)=\frac{\Gamma(a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1}$</p>
</li>
<li>$\displaystyle\mathbb{E}[\mu]=\frac{a}{a+b}$</li>
<li>
<p>$\displaystyle\operatorname{var}[\mu]=\frac{a b}{(a+b)^2(a+b+1)}$</p>
</li>
<li>
<p>狄利克雷分布 ——贝塔分布的多元扩展</p>
</li>
<li>
<p>多个连续变量 $\mu_i \in[0,1]$ 的概率分布，满足 $\sum_i \mu_i=1$</p>
</li>
<li>$\displaystyle\operatorname{Dir}(\boldsymbol{\mu} \mid \boldsymbol{\alpha})=\frac{\Gamma\left(\sum_i \alpha_i\right)}{\Pi_i \Gamma\left(\alpha_i\right)} \prod_i \mu_i^{\alpha_i-1}$</li>
<li>
<p>$\displaystyle\mathbb{E}\left[\mu_i\right]=\frac{\alpha_i}{\sum_i \alpha_i}$</p>
</li>
<li>
<p>伽马分布 ——$\tau&gt;0$</p>
</li>
<li>
<p>$\displaystyle\operatorname{Gam}(\tau \mid a, b)=\frac{1}{\Gamma(a)} b^a \tau^{a-1} e^{-b \tau}$</p>
</li>
<li>$\displaystyle\mathbb{E}[\tau]=\frac{a}{b}$</li>
<li>$\displaystyle\operatorname{var}[\tau]=\frac{a}{b^2}$</li>
</ul>
<h4 id="_13">熵</h4>
<p>当取自有限的样本时，熵的公式可以表示为：（注意负号）
$$
\mathrm{H}(X)=\sum_i \mathrm{P}\left(x_i\right) \mathrm{I}\left(x_i\right)=-\sum_i \mathrm{P}\left(x_i\right) \log _b \mathrm{P}\left(x_i\right)
$$
这里 $b$ 是底，通常可以是 2，e 或 10.</p>
<p>还可以定义事件 $X$ 与 $Y$ 分别取 $x_i$ 和 $y_j$ 时的条件熵为
$$
\mathrm{H}(X \mid Y)=-\sum_{i, j} p\left(x_i| y_j\right) \log \frac{p\left(x_i| y_j\right)}{p\left(y_j\right)}
$$</p>
<h4 id="kl">KL 散度</h4>
<p>衡量两个分布的差异</p>
<ul>
<li>$D_{K L}(P | Q)=\mathbb{E}_{x \sim P}\left[\log \frac{P(x)}{Q(x)}\right]$</li>
<li>非负, $\mathrm{P}=\mathrm{Q}$ 时为零</li>
<li>$D_{K L}(P | Q) \neq D_{K L}(Q | P)$ ，但理论上最小值均当 $\mathrm{P}=\mathrm{Q}$</li>
</ul>
<p>$$
D_{K L}(P | Q)=\mathbb{E}<em>{x \sim P}\left[\log \frac{P(x)}{Q(x)}\right]=\mathbb{E}</em>{x \sim P}[\log P(x)]-\mathbb{E}_{x \sim P}[\log Q(x)]
$$</p>
<ul>
<li>即 P 和 Q 的 KL 散度等于 $-H(P)+H(P,Q)$，后者称之为交叉熵。</li>
</ul>
<h3 id="_14">优化</h3>
<h4 id="_15">凸集和凸函数</h4>
<p><strong>凸集</strong></p>
<p>给定集合 $C \subseteq \mathbb{R}^n$ 。若 $\forall x, y \in C$ 满足
$$
\forall t \in[0,1], t x+(1-t) y \in C
$$
那么集合 $C$ 为凸集。</p>
<p><strong>凸函数</strong></p>
<p>给定一个函数 $f:\R^n→\R$，如果 domain(f) 是凸集，且任意 $x,y\in domain(f),$
$$
\forall t \in[0,1], f(t x+(1-t) y) \leq t f(x)+(1-t) f(y)
$$
那么函数 $f$ 是凸函数。</p>
<p><strong>凸函数例子</strong>：</p>
<ul>
<li>
<p>指数函数 $\exp (a x)$</p>
</li>
<li>
<p>负对数函数 $-\log (x)$</p>
</li>
<li>反射函数 $\boldsymbol{a}^{\top} \boldsymbol{x}+b$</li>
<li>二次函数 $x^{\top} A \boldsymbol{x}+2 \boldsymbol{b}^{\top} \boldsymbol{x}+c \quad(A$ 半正定 $)$</li>
<li>范数 $|x|_p=\sqrt[p]{\sum_i\left|x_i\right|^p}$</li>
<li>最大函数 $f(x)=\max \left{x_1, \cdots, x_n\right}$</li>
<li>Softplus $\log (1+\exp (x))$</li>
<li>LogSumExp $\log \left(\sum_i \exp \left(x_i\right)\right)$</li>
<li>LogDeterminant $-\log \operatorname{det}(X)$ 在半正定矩阵定义域上</li>
</ul>
<p><strong>一阶条件</strong></p>
<p>假设函数 $f$ 可微，那么 $f$ 是凸函数当且仅当 $∀ x,y∈dom(f)$，
$$
f(y)≥f(x)+∇f(x)^⊤ (y-x)
$$
即 —— 函数在切线上方。</p>
<p><strong>二阶条件</strong></p>
<p>假设函数 $f$ 二阶可微，那么 $f$ 是凸函数当且仅当 $∀ x∈dom(f)$，
$$
∇^2 f(x)≽0
$$
 即 —— 海森矩阵半正定。</p>
<h4 id="_16">优化问题</h4>
<p><strong>优化问题</strong>
$$
\begin{array}{cl} 
&amp; \min _x f(x) \
\text { s.t. } &amp; g_i(x) \leq 0, i=1,2, \ldots, m \
&amp; h_j(x)=0, j=1,2, \cdots, n
\end{array}
$$
这里的 $s.t.$ 是 subject to，意为 “在……的约束下”。</p>
<p><strong>凸优化问题</strong>
$$
\begin{gathered}
\min _x f(\boldsymbol{x}) \
\text { s.t. } g_i(\boldsymbol{x}) \leq 0, i=1,2, \ldots, m \
\boldsymbol{a}_i^{\top} \boldsymbol{x}=b, j=1,2, \cdots, n
\end{gathered}
$$
其中 $f(\boldsymbol{x}), g_i(\boldsymbol{x})$ 是凸函数。</p>
<ul>
<li>凸优化中，局部最优等价于全局最优。假设函数 $f$ 可微凸函数，那么 $x$ 是 $f$ 的全局最优当且仅当 $∇f(\mathbf{x})=0$。</li>
</ul>
<p><strong>无约束优化：梯度下降</strong></p>
<p>目标： $\min <em>x f(x)$
$$
\begin{aligned}
&amp;\text { while }\left|\nabla f\left(x_t\right)\right|&gt;\delta \text { do } \
&amp;\quad \boldsymbol{x}</em>{t+1} \leftarrow \boldsymbol{x}<em>t-\alpha \nabla f\left(\boldsymbol{x}_t\right) \
&amp;\text { end while }
\end{aligned}
$$
<strong>有约束优化：KKT条件（拉格朗日乘子法）</strong>
$$
\begin{array}{cc} 
&amp; \min </em>{\boldsymbol{x}} f(\boldsymbol{x}) \
\text { s.t. } &amp; g_i(\boldsymbol{x}) \leq 0, i=1,2, \ldots, m \
&amp; h_j(\boldsymbol{x})=0, j=1,2, \cdots, n
\end{array}
$$
引入拉格朗日函数：
$$
L(\boldsymbol{x}, \boldsymbol{u}, \boldsymbol{v})=f(\boldsymbol{x})+\sum_i u_i g_i(\boldsymbol{x})+\sum_j v_j h_j(\boldsymbol{x})
$$
其中 $u_i \geq 0$。</p>
<p>最优解的<strong>必要条件：KKT条件</strong>
$$
\begin{gathered}
\boldsymbol{\nabla}_{\mathbf{x}} L(\boldsymbol{x}, \boldsymbol{u}, \boldsymbol{v})=\mathbf{0} \
g_i(\boldsymbol{x}) \leq 0 \
h_j(\boldsymbol{x})=0 \
\mu_i \geq 0 \
\mu_i g_i(\boldsymbol{x})=0
\end{gathered}
$$
最后一个式子表明只有 $\mu_i=0$ 或者 $g_i(x)=0$。</p>
<p><strong>取一个简单的示例做解释</strong>：</p>
<p>令 $L(x,\mu)=f(x)+\sum_i\mu_ig_i(x)$，因为 $\mu g(x)\le0$，所以 $\displaystyle\max_\mu L(x,\mu)=f(x)$（🤑）。</p>
<p>所以目标函数变为（称之为 $x\mu$ 问题）
$$
\min <em>x f(x)=\min _x \max </em>\mu L(x, \mu)
$$
如果对等号右边那一项交换顺序（称之为 $\mu x$ 问题）
$$
\begin{aligned}
\max <em>\mu \min _x L(x, \mu)&amp;=\max </em>\mu\left[\min <em>x f(x)+\min _x \mu g(x)\right]（按定义展开）\&amp;=\max </em>\mu \min <em>x f(x)+\max </em>\mu \min <em>x \mu g(x)（分配算子，这一步可略）\&amp;=\min _x f(x)+\max </em>\mu \min <em>x \mu g(x)（第一项不受\mu约束）
\end{aligned}
$$
然后我们观察
$$
\left.\begin{array}{c}
\mu_k \geq 0 \
g_k(x) \leq 0
\end{array}\right}=&gt;\min _x \mu g(x)=\left{\begin{array}{cc}
0 &amp; \text { if } \mu=0 \text { or } g(x)=0 \
-\infty &amp; \text { if } \mu&gt;0 \text { and } g(x)&lt;0
\end{array}\right.
$$
说明 
$$
\max </em>\mu \min <em>x \mu g(x)=0 \text { 此时 } \mu=0 \text { or } g(x)=0
（😄）
$$
就是说 
$$
\max </em>\mu \min <em>x L(x, \mu)=\min _x f(x)+\max </em>\mu \min <em>x \mu g(x)=\min _x f(x)（😟）
$$
这说明 $\min _x \max </em>\mu L(x, \mu)=\max <em>\mu \min _x L(x, \mu)$，两个算子可以交换顺序
$$
\left.\begin{array}{c}
L(x, \mu)=f(x)+\sum</em>{k=1}^q \mu_k g_k(x) \
\mu_k \geq 0 \
g_k(x) \leq 0
\end{array}\right}=&gt;\min <em>x \max </em>\mu L(x, \mu)=\max _\mu \min _x L(x, \mu)=\min _x f(x)
$$
这就说明如果满足条件（😄），互为对偶的两个问题 $x\mu,\mu x$ 的解和 $\min_x f(x)$ 是相同的。</p>
<p>设这个最优解是 $\xi$，则 $x=\xi$ 时 $\mu=0$ 或 $g(\xi)=0$。带入（🤑）中，有 
$$
\max_\mu L(\xi,\mu)=f(\xi)
$$
又由（😟）得【注意到 $f(\xi)=\min_xf(x)$】
$$
\max _\mu \min _x L(x, \mu)=f(\xi)
$$
所以
$$
L(\xi,\mu)=\min_xL(x,\mu)
$$
说明 $\xi$ 也是 $L(x,\mu)$ 的极值点，后者在这点的偏 $x$ 导数为 0。</p>
<p>结论就是：
$$
\left.\begin{array}{c}
L(x, \mu)=f(x)+\sum_{k=1}^q \mu_k g_k(x) \
\mu_k \geq 0 \
g_k(x) \leq 0
\end{array}\right}=&gt;\left{\begin{array}{c}
\min <em>x \max </em>\mu L(x, \mu)=\max <em>\mu \min _x L(x, \mu)=\min _x f(x)=f\left(\xi\right) \
\mu_k g_k\left(\xi\right)=0 \
\left.\frac{\partial L(x, \mu)}{\partial x}\right|</em>{x=\xi}=0
\end{array}\right.
$$
KKT 条件总结起来就是：
$$
\left.\begin{array}{c}
L(x, \lambda, \mu)=f(x)+\sum_{i=1}^n \lambda_i h_i(x)+\sum_{k=1}^q \mu_k g_k(x) \
\lambda_i \neq 0 \
h_i(x)=0 \
\mu_k \geq 0 \
g_k(x) \leq 0
\end{array}\right}=&gt;\left{\begin{array}{c}
\min <em>x \max </em>\mu L(x, \lambda, \mu)=\max <em>\mu \min _x L(x, \lambda, \mu)=\min _x f(x)=f\left(\xi\right) \
\mu_k g_k\left(\xi\right)=0 \
\left.\frac{\partial L(x, \lambda, \mu)}{\partial x}\right|</em>{x=\xi}=0
\end{array}\right.
$$
注: $x, \lambda, \mu$ 都是向量。</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="页脚" >
      
        
        <a href=".." class="md-footer__link md-footer__link--prev" aria-label="上一页: Welcome to MkDocs" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                上一页
              </span>
              Welcome to MkDocs
            </div>
          </div>
        </a>
      
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\s\\-\uff0c\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.37e9125f.min.js"></script>
      
    
  </body>
</html>