<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>模型评估与选择 - Notes Site</title>
    <link href="../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "\u603b\u4f53\u4efb\u52a1", url: "#_top", children: [
          ]},
          {title: "\u6982\u5ff5", url: "#_2", children: [
          ]},
          {title: "\u6a21\u578b\u8bc4\u4f30\u65b9\u6cd5", url: "#_3", children: [
              {title: "\u603b\u4f53\u8981\u6c42", url: "#_4" },
              {title: "\u7559\u51fa\u6cd5\uff08hold out\uff09", url: "#hold-out" },
              {title: "\u4ea4\u53c9\u9a8c\u8bc1\uff08cross validation\uff09", url: "#cross-validation" },
              {title: "\u81ea\u52a9\u6cd5\uff08bootstrapping\uff09", url: "#bootstrapping" },
          ]},
          {title: "\u6a21\u578b\u8bc4\u4f30\u7684\u6027\u80fd\u5ea6\u91cf", url: "#_5", children: [
              {title: "\u5747\u65b9\u8bef\u5dee", url: "#_6" },
              {title: "\u9519\u8bef\u7387\u548c\u7cbe\u5ea6", url: "#_7" },
              {title: "\u6df7\u6dc6\u77e9\u9635", url: "#_8" },
              {title: "\u53d7\u8bd5\u8005\u5de5\u4f5c\u7279\u5f81\uff08Receiver Operating Characteristics\uff09", url: "#receiver-operating-characteristics" },
              {title: "\u4ee3\u4ef7\u66f2\u7ebf", url: "#_9" },
          ]},
          {title: "\u6a21\u578b\u8bc4\u4f30\u7684\u6bd4\u8f83\u65b9\u6cd5", url: "#_10", children: [
              {title: "\u4e8c\u9879\u68c0\u9a8c", url: "#_11" },
              {title: "tt \u68c0\u9a8c", url: "#tt" },
              {title: "\u4ea4\u53c9\u9a8c\u8bc1 tt \u68c0\u9a8c\uff08\u6210\u5bf9\uff09", url: "#tt_1" },
              {title: "McNemar \u68c0\u9a8c", url: "#mcnemar" },
              {title: "Friedman \u68c0\u9a8c", url: "#friedman" },
              {title: "Nemenyi \u540e\u7eed\u68c0\u9a8c", url: "#nemenyi" },
          ]},
          {title: "\u6cdb\u5316\u6027\u80fd\u89e3\u91ca", url: "#_12", children: [
          ]},
        ];

    </script>
    <script src="../../../js/base.js"></script>
      <script src="../../../mathjax-config.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../3_%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/1_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../3_%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/1_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="btn btn-xs btn-link">
        1 线性回归
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/3_%E4%BC%98%E5%8C%96/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/3_%E4%BC%98%E5%8C%96/" class="btn btn-xs btn-link">
        3 优化
      </a>
    </div>
    
  </div>

    

    <h2 id="_1">总体任务</h2>
<ol>
<li>给定一个数据集，如何估计一个模型的“泛化” 能力？</li>
<li>给定一个数据集，如何根据“泛化” 能力，选出最好的模型或选出最好的参数配置</li>
</ol>
<h2 id="_2">概念</h2>
<p><strong>误差</strong>：样本真实输出与预测输出之间的差异。</p>
<blockquote>
<p>训练集上的误差称为<strong>训练误差</strong>或<strong>经验误差</strong>；</p>
<p>测试集上的误差称为<strong>测试误差</strong>；</p>
<p>除了训练集外的所有样本上的误差称为<strong>泛化误差</strong>。</p>
</blockquote>
<p><strong>过拟合</strong>：学习器把训练样本学习的“太好”，将训练样本本身的特点当做所有样本的一般性质，导致泛化性能下降。</p>
<blockquote>
<p><strong>解决办法</strong>：优化目标加正则项；early stop</p>
</blockquote>
<p><strong>欠拟合</strong>：对训练样本的一般性质尚未学好。</p>
<blockquote>
<p><strong>解决办法</strong>：（决策树）拓展分支；（神经网络）增加训练轮数</p>
</blockquote>
<h2 id="_3">模型评估方法</h2>
<h4 id="_4">总体要求</h4>
<ol>
<li>需要一个<strong>测试集</strong>来测试学习器对新样本的判别能力</li>
<li>假设测试集是从样本真实分布中<strong>独立采样</strong>获得，以测试集上的测试误差作为泛化误差的近似</li>
<li>测试样本尽量不在训练集中出现、未在训练集中使用过</li>
</ol>
<h4 id="hold-out">留出法（hold out）</h4>
<p><strong>方法</strong>：</p>
<ol>
<li>直接将数据集 <span class="arithmatex"><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span> 划分为两个互斥的集合 <span class="arithmatex"><span class="MathJax_Preview">S,T</span><script type="math/tex">S,T</script></span></li>
<li>在 <span class="arithmatex"><span class="MathJax_Preview">S</span><script type="math/tex">S</script></span> 上训练出模型后用 <span class="arithmatex"><span class="MathJax_Preview">T</span><script type="math/tex">T</script></span> 来评估其测试误差并作为泛化误差的估计</li>
<li>若干次随机划分、重复进行实验评估后取平均值作为评估结果</li>
</ol>
<p><strong>注意</strong>：</p>
<ol>
<li>分层采样，保证 <span class="arithmatex"><span class="MathJax_Preview">S,T</span><script type="math/tex">S,T</script></span> 的数据分布一致</li>
<li>对偏差-方差的窘境，做法是用 <span class="arithmatex"><span class="MathJax_Preview">\frac{2}{3}\sim\frac{4}{5}</span><script type="math/tex">\frac{2}{3}\sim\frac{4}{5}</script></span> 的数据集用于训练</li>
</ol>
<h4 id="cross-validation">交叉验证（cross validation）</h4>
<p><strong>方法</strong>：</p>
<ol>
<li>将数据集分层采样划分为 <span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 个大小相似的互斥子集</li>
<li>每次用 <span class="arithmatex"><span class="MathJax_Preview">k-1</span><script type="math/tex">k-1</script></span> 个子集的并集作为训练集，余下的子集作为测试集</li>
<li>最终返回 <span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 个测试结果的均值</li>
</ol>
<p><strong>注意</strong>：</p>
<ol>
<li>根据 <span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 的取值，称之为 <span class="arithmatex"><span class="MathJax_Preview">k\text{-fold}</span><script type="math/tex">k\text{-fold}</script></span> 交叉验证</li>
<li>为了排除数据划分引入的差别，<span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 折交叉验证通常<strong>随机使用不同的划分</strong>重复 <span class="arithmatex"><span class="MathJax_Preview">p</span><script type="math/tex">p</script></span> 次，最终的评估结果取所有结果的均值（如10次10折交叉验证就是做了100次“训练-测试”）</li>
<li><span class="arithmatex"><span class="MathJax_Preview">k</span><script type="math/tex">k</script></span> 值大小的权衡实际上是<strong>数据划分因素</strong>与<strong>计算复杂度</strong>之间的权衡</li>
</ol>
<p><strong>留一法（Leave-One-Out, LOO）</strong>：</p>
<ul>
<li>每个样本一个集合（<span class="arithmatex"><span class="MathJax_Preview">k=\text{size}</span><script type="math/tex">k=\text{size}</script></span>）</li>
<li>不受随机样本划分方式的影响，结果往往比较准确</li>
<li>当数据集比较大时，计算开销难以忍受</li>
</ul>
<h4 id="bootstrapping">自助法（bootstrapping）</h4>
<p><strong>前面两种方法的问题</strong>：希望评估 <span class="arithmatex"><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span> 训练出的模型，但是实际评估模型使用了更小数据集，对保真性造成了影响</p>
<p><strong>方法</strong>：</p>
<ol>
<li>从 <span class="arithmatex"><span class="MathJax_Preview">D</span><script type="math/tex">D</script></span> 中做 <span class="arithmatex"><span class="MathJax_Preview">\text{size}(D)</span><script type="math/tex">\text{size}(D)</script></span> 次有放回抽样，得 <span class="arithmatex"><span class="MathJax_Preview">D'</span><script type="math/tex">D'</script></span></li>
<li>将 <span class="arithmatex"><span class="MathJax_Preview">D'</span><script type="math/tex">D'</script></span> 用作训练集，用 <span class="arithmatex"><span class="MathJax_Preview">D-D'</span><script type="math/tex">D-D'</script></span> 作测试集</li>
</ol>
<p><strong>注意</strong>：</p>
<ol>
<li>实际模型与预期模型都使用 <span class="arithmatex"><span class="MathJax_Preview">\text{size}(D)</span><script type="math/tex">\text{size}(D)</script></span> 个训练样本</li>
<li>约有1/3（极限1/e）的样本没在训练集中出现</li>
<li>自助法在数据集较小、难以有效划分训练/测试集时很有用</li>
<li>由于<strong>改变了数据集分布</strong>可能引入估计偏差，在数据量足够时，留出法和交叉验证法更常用</li>
</ol>
<blockquote>
<p>从初始数据集中产生多个不同的训练集，对<strong>集成学习</strong>有很大的好处。</p>
<p><strong>集成学习</strong>：一种技术框架，其按照不同的思路来<strong>组合</strong>基础模型，从而达到更好的目的。</p>
</blockquote>
<h2 id="_5">模型评估的性能度量</h2>
<p>给定样例集 <span class="arithmatex"><span class="MathJax_Preview">D=\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_m,y_m)\}</span><script type="math/tex">D=\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_m,y_m)\}</script></span>，性能度量函数 <span class="arithmatex"><span class="MathJax_Preview">F</span><script type="math/tex">F</script></span> 需要比较预测结果 <span class="arithmatex"><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> 和真实标记</p>
<h4 id="_6">均方误差</h4>
<p>回归任务最常用的性能度量
$$
F=\mathbb{E}(f,D)=\frac{1}{m}\sum_i[f(\mathbf{x}_i)-y_i]^2
$$
假设知道数据的分布，那么均方误差表达为
$$
F=\mathbb{E}(f,D)=\int_D[f(\mathbf{x})-y]^2p(\mathbf{x})d\mathbf{x}
$$</p>
<h4 id="_7">错误率和精度</h4>
<p>错误率：<strong>分错类的样本</strong>占样本总数的比例
$$
F=\mathbb{E}(f,D)=\frac{1}{m}\sum_i\mathbb{I}[f(x_i)\ne y_i]
$$
精度：分对样本占样本总数的比率
$$
\text{acc}(f,D)=1-\mathbb{E}(f,D)
$$</p>
<h4 id="_8">混淆矩阵</h4>
<p><img alt="image-20220925202612011" src="../chap1.assets/image-20220925202612011.png" /></p>
<p><strong>真正例TP</strong>：判断为正例（P），判断是正确的（T），实际是正例</p>
<p><strong>真反例TN</strong>：判断为负例（N），判断是正确的（T），实际就是负例</p>
<p><strong>假正例FP</strong>：判断为正例（P），判断是错误的（T），实际是负例</p>
<p><strong>假反例FN</strong>：判断为负例（N），判断是错误的（T），实际是正例</p>
<p><strong>查准率（P, 精度）</strong>：判断为正例中，真正是正例的比例
$$
P=\frac{TP}{TP+FP}
$$
<strong>查全率（R, 召回率）</strong>：判断为正例的，占真正正例的比例
$$
R=\frac{TP}{TP+FN}
$$
<strong>注意</strong>：</p>
<ol>
<li>
<p>查准率和查全率是一堆矛盾的度量</p>
</li>
<li>
<p>根据学习器的预测结果按<strong>正例可能性大小</strong>对样例进行排序，并逐个把样本作为正例进行预测，每次可以计算出当前 <span class="arithmatex"><span class="MathJax_Preview">P</span><script type="math/tex">P</script></span> 和 <span class="arithmatex"><span class="MathJax_Preview">R</span><script type="math/tex">R</script></span>，遍历之后可以得到 <span class="arithmatex"><span class="MathJax_Preview">P-R</span><script type="math/tex">P-R</script></span> 曲线</p>
</li>
<li>
<p>如果一个学习器的 <span class="arithmatex"><span class="MathJax_Preview">P-R</span><script type="math/tex">P-R</script></span> 曲线被另一个学习器的曲线完全包住，那么后者性能更优</p>
</li>
<li>
<p>如果发生了交叉，则难以判断孰优孰劣。</p>
</li>
</ol>
<blockquote>
<ul>
<li>通过<strong>平衡点</strong>来权衡这两者指标</li>
</ul>
<p>平衡点是曲线上“查准率=查全率”时的取值，可用来用于度量 <span class="arithmatex"><span class="MathJax_Preview">P-R</span><script type="math/tex">P-R</script></span> 曲线有交叉的分类器性能高低。</p>
<ul>
<li>
<p>通过 <span class="arithmatex"><span class="MathJax_Preview">F1</span><script type="math/tex">F1</script></span> 度量来评估学习器优劣
  $$
  F1=\frac{2PR}{P+R}=\left[\frac{1}{2}\left(\frac{1}{P}+\frac{1}{R}\right)\right]^{-1}
  $$</p>
</li>
<li>
<p>更一般的形式是 <span class="arithmatex"><span class="MathJax_Preview">F_\beta</span><script type="math/tex">F_\beta</script></span>
  $$
  F_\beta=\frac{\left(1+\beta^2\right) \times P \times R}{\beta^2 P+R}=\frac{\frac{1}{\beta}+\beta}{\left(\frac{1}{\beta} \frac{1}{P}+\beta \frac{1}{R}\right)}
  $$
  <span class="arithmatex"><span class="MathJax_Preview">\beta &gt;1</span><script type="math/tex">\beta >1</script></span> 时偏重查全率，<span class="arithmatex"><span class="MathJax_Preview">\beta &lt; 1</span><script type="math/tex">\beta < 1</script></span> 时偏重查准率。</p>
</li>
</ul>
</blockquote>
<p><strong>多个混淆矩阵的情况</strong>：</p>
<ul>
<li><strong>宏</strong>：先在各个混淆矩阵上分别计算出查准率和查全率等指标，再求平均。</li>
<li><strong>微</strong>：先在各个混淆矩阵对应元素平均，得到TP、FP、TN、FN的平均值，在基于平均值计算查准率等指标。</li>
</ul>
<h4 id="receiver-operating-characteristics">受试者工作特征（Receiver Operating Characteristics）</h4>
<p><strong>真正例率TPR</strong>：在所有真实正例当中，正确判断为正例的占的比例，实际就是精度
$$
TPR=\frac{TP}{TP+FN}
$$
<strong>假正例率FPR</strong>：在所有真实负例当中， 错误判断为正例所占的比例
$$
FPR=\frac{FP}{FP+TN}
$$
<strong>绘制ROC的方法</strong>：</p>
<ol>
<li>有 <span class="arithmatex"><span class="MathJax_Preview">m^+</span><script type="math/tex">m^+</script></span> 个正例、<span class="arithmatex"><span class="MathJax_Preview">m^-</span><script type="math/tex">m^-</script></span> 个负例，根据学习器预测结果 <span class="arithmatex"><span class="MathJax_Preview">f(x)</span><script type="math/tex">f(x)</script></span> 排序。</li>
<li>将分类阈值设为每个样例的预测值</li>
<li>若当前为真正例，则向 <span class="arithmatex"><span class="MathJax_Preview">y</span><script type="math/tex">y</script></span> 轴步进 <span class="arithmatex"><span class="MathJax_Preview">1/m^+</span><script type="math/tex">1/m^+</script></span>；若当前为假正例，则向 <span class="arithmatex"><span class="MathJax_Preview">x</span><script type="math/tex">x</script></span> 轴步进 <span class="arithmatex"><span class="MathJax_Preview">1/m^-</span><script type="math/tex">1/m^-</script></span></li>
</ol>
<p><strong>注意</strong>：</p>
<ol>
<li>若某个学习器的ROC曲线被另一个学习器的曲线“包住”，则后者性能优于前者</li>
<li>如果曲线交叉，可以根据ROC曲线下面积大小进行比较，也即AUC值（Area Under Curve）</li>
<li>AUC衡量了样本预测的排序质量</li>
</ol>
<h4 id="_9">代价曲线</h4>
<p>现实任务中不同类型的错误所造成的后果很可能不同，为了权衡<strong>不同类型错误</strong>所造成的<strong>不同损失</strong>，可为错误赋予“非均等代价”。</p>
<p><img alt="image-20220925223225630" src="../chap1.assets/image-20220925223225630.png" /></p>
<p><strong>平均代价（性能度量指标）</strong>：</p>
<div class="arithmatex">
<div class="MathJax_Preview">
E(f ; D, \cos t)=\frac{1}{m}\left(\sum_{x_i \in D^{+}} \mathbb{I}\left(f\left(x_i\right) \neq y_i\right) \times \operatorname{cost}_{01}+\sum_{x_i \in D^{-}} \mathbb{I}\left(f\left(x_i\right) \neq y_i\right) \times \operatorname{cost}_{10}\right)
</div>
<script type="math/tex; mode=display">
E(f ; D, \cos t)=\frac{1}{m}\left(\sum_{x_i \in D^{+}} \mathbb{I}\left(f\left(x_i\right) \neq y_i\right) \times \operatorname{cost}_{01}+\sum_{x_i \in D^{-}} \mathbb{I}\left(f\left(x_i\right) \neq y_i\right) \times \operatorname{cost}_{10}\right)
</script>
</div>
<p>在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而“代价曲线”可以。</p>
<p><em>具体怎么做，我猜不考，就不学了吧：）</em></p>
<h2 id="_10">模型评估的比较方法</h2>
<p>做性能比较要考虑的事情：</p>
<ol>
<li>测试性能（测试集上表现的）并不等于泛化性能</li>
<li>测试性能随着测试集的变化而变化</li>
<li>很多机器学习算法本身有一定的随机性</li>
</ol>
<p>所以直接选取相应评估方法在相应度量下比大小的方法不可取。——<strong>假设检验</strong>！</p>
<h4 id="_11">二项检验</h4>
<h4 id="tt"><span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span> 检验</h4>
<p>多次留出法或交叉验证法进行训练/测试时可使用 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span> 检验。</p>
<h4 id="tt_1">交叉验证 <span class="arithmatex"><span class="MathJax_Preview">t</span><script type="math/tex">t</script></span> 检验（成对）</h4>
<h4 id="mcnemar">McNemar 检验</h4>
<h4 id="friedman">Friedman 检验</h4>
<h4 id="nemenyi">Nemenyi 后续检验</h4>
<h2 id="_12">泛化性能解释</h2>
<p>假设噪声的期望为 0，即 <span class="arithmatex"><span class="MathJax_Preview">\mathbb{E}_D(y_D-y)=0</span><script type="math/tex">\mathbb{E}_D(y_D-y)=0</script></span>。</p>
<p>对泛化误差分解：
$$
\begin{aligned}
E(f, D) &amp;=\mathbb{E}_D\left[\left(f(\boldsymbol{x} ; D)-y_D\right)^2\right] \newline
&amp;=\mathbb{E}_D\left[\left(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x})+\bar{f}(\boldsymbol{x})-y_D\right)^2\right] \newline
&amp;=\mathbb{E}_D\left[(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x}))^2\right]+\mathbb{E}_D\left[\left(\bar{f}(\boldsymbol{x})-y_D\right)^2\right] \newline
&amp;=\mathbb{E}_D\left[(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x}))^2\right]+\mathbb{E}_D\left[\left(\bar{f}(\boldsymbol{x})-y+y-y_D\right)^2\right] \newline
&amp;=\mathbb{E}_D\left[(f(\boldsymbol{x} ; D)-\bar{f}(\boldsymbol{x}))^2\right]+\mathbb{E}_D\left[(\bar{f}(\boldsymbol{x})-y)^2\right]+\mathbb{E}_D\left[\left(y-y_D\right)^2\right] \newline
&amp;=\text{Var}(\boldsymbol{x})+\text{bias}(\boldsymbol{x})+\varepsilon^2
\end{aligned}
$$</p>
<ul>
<li>方差度量了同样大小训练集的变动所导致的学习性能的变化；即刻画了数据扰动所造成的影响</li>
<li>偏差度量了学习算法期望预测与真实结果的偏离程度；即刻画了学习算法本身的拟合能力</li>
<li>噪声表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界；即刻画了学习问题本身的难度</li>
</ul>
<p>泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给定学习任务为了取得好的泛化性能，需要使偏差小（充分拟合数据）而且方差较小（减少数据扰动产生的影响）。</p>
<p>一般来说，偏差与方差是有冲突的，称为偏差-方差窘境。</p>
<ul>
<li>
<p>在训练不足时，学习器拟合能力不强，训练数据的扰动不足以使学习器的拟合能力产生显著变化，此时偏差主导泛化错误率</p>
</li>
<li>
<p>随着训练程度加深，学习器拟合能力逐渐增强，方差逐渐主导泛化错误率</p>
</li>
<li>
<p>训练充足后，学习器的拟合能力非常强，训练数据的轻微扰动都会导致学习器的显著变化，若训练数据自身非全局特性被学到则会发生过拟合。</p>
</li>
</ul>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../../3_%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/1_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../../3_%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/1_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/" class="btn btn-xs btn-link">
        1 线性回归
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../../1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/3_%E4%BC%98%E5%8C%96/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../../1_%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/3_%E4%BC%98%E5%8C%96/" class="btn btn-xs btn-link">
        3 优化
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
  <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>